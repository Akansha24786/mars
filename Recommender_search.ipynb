{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recommender_search.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akansha24786/mars/blob/master/Recommender_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TSrHAsSALXj"
      },
      "source": [
        "## Pre-req"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SraANikoSVqR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62bb6844-fc60-4d4f-eb49-0af168fe62ad"
      },
      "source": [
        "!gdown --id 1dJVSSk8gFdjMs002N7oKDOthQKxFeuxT"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1dJVSSk8gFdjMs002N7oKDOthQKxFeuxT\n",
            "To: /content/filtered.csv\n",
            "20.9MB [00:00, 44.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaiTxhvkfG-e"
      },
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import spacy\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "EN = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "hNvybiD9_-H8",
        "outputId": "9482071f-97bc-4b98-c75a-19978a823a59"
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('filtered.csv')\n",
        "df=df.replace('\\r', ' ', regex=True)\n",
        "df=df.replace('\\n', ' ', regex=True)\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Issue key</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Description</th>\n",
              "      <th>Custom field (Product L1 Name)</th>\n",
              "      <th>Custom field (Product L2 Name)</th>\n",
              "      <th>Custom field (Product L3 Name)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>P10051779-113937</td>\n",
              "      <td>[Renesas R-CAR TOP] Huge number of repeaters a...</td>\n",
              "      <td>Hello,    We are currently working on a top le...</td>\n",
              "      <td>IC Compiler II</td>\n",
              "      <td>Pre-route Buffering</td>\n",
              "      <td>HFS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>P10051779-114429</td>\n",
              "      <td>assign status on signal nets</td>\n",
              "      <td>Hi,    Assign statement is seen in Verilog out...</td>\n",
              "      <td>IC Compiler II</td>\n",
              "      <td>Pre-route Buffering</td>\n",
              "      <td>Other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>P10051779-114676</td>\n",
              "      <td>initial_drc leaves inverters away from straps</td>\n",
              "      <td>dual-rail cells are away from straps after opt...</td>\n",
              "      <td>IC Compiler II</td>\n",
              "      <td>Pre-route Buffering</td>\n",
              "      <td>MV Buffering</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>P10051779-85889</td>\n",
              "      <td>initial_drc step of place_opt remove buffer an...</td>\n",
              "      <td>Hi,  My customer is using ICC2 18.06-SP4 and h...</td>\n",
              "      <td>IC Compiler II</td>\n",
              "      <td>Pre-route Buffering</td>\n",
              "      <td>HFS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>P10051779-86232</td>\n",
              "      <td>PV REG: optimization log file increase 2X w/ l...</td>\n",
              "      <td>Hi James,  Regression Case:  preroute_opt/drc/...</td>\n",
              "      <td>IC Compiler II</td>\n",
              "      <td>Pre-route Buffering</td>\n",
              "      <td>HFS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ... Custom field (Product L3 Name)\n",
              "0           0  ...                            HFS\n",
              "1           1  ...                          Other\n",
              "2           2  ...                   MV Buffering\n",
              "3           3  ...                            HFS\n",
              "4           4  ...                            HFS\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC1YZ0assdRK",
        "outputId": "49c81b13-dd1c-4163-b498-bd8feaf81236"
      },
      "source": [
        "c=0\n",
        "for i in range(len(df)):\n",
        "    if isinstance(df['Summary'][i], float):\n",
        "        df['Summary'][i]=' '\n",
        "    if isinstance(df['Description'][i], float):\n",
        "        df['Description'][i]=' '\n",
        "\n",
        "\n",
        "\n",
        "for i in range(len(df)):\n",
        "    if isinstance(df['Summary'][i], float):\n",
        "        c+=1\n",
        "print(c)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqYU9aQPSwiD"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "P7GkfPlN3qxd",
        "outputId": "58e012cc-90af-4c15-c3fe-7afe0dcdbf4d"
      },
      "source": [
        "df[df['Issue key']=='P10051779-166505']"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Issue key</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Description</th>\n",
              "      <th>Custom field (Product L1 Name)</th>\n",
              "      <th>Custom field (Product L2 Name)</th>\n",
              "      <th>Custom field (Product L3 Name)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>198</td>\n",
              "      <td>P10051779-166505</td>\n",
              "      <td>initial_drc create detour buffer tree</td>\n",
              "      <td>place_opt -from initial_drc -to initial_drc cr...</td>\n",
              "      <td>IC Compiler II</td>\n",
              "      <td>Pre-route Buffering</td>\n",
              "      <td>HFS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0  ... Custom field (Product L3 Name)\n",
              "198         198  ...                            HFS\n",
              "\n",
              "[1 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmHBwYoIc6cC"
      },
      "source": [
        "# Make a dict having tag frequencies\n",
        "tag_freq_dict = {}\n",
        "for tag in df['Custom field (Product L2 Name)']:\n",
        "        if tag not in tag_freq_dict:\n",
        "            tag_freq_dict[tag] = 0\n",
        "        else:\n",
        "            tag_freq_dict[tag] += 1"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EnVr3OjfN3v",
        "outputId": "d6aa0f83-7d9c-4cdb-a1e1-97600eb92d4e"
      },
      "source": [
        "print(tag_freq_dict)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Pre-route Buffering': 1198, 'Pre-route Opt': 3603, 'Placement - Coarse Placer': 1686, 'Chip Finish - Placement': 489, 'Relative Placement': 316, 'Magnet Placement': 15, 'Timing Analysis': 4645, 'Power Analysis': 1068, 'Custom field (Product L2 Name)': 0, nan: 13}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXnkPkMVfFzk",
        "outputId": "30ff8593-4c88-4a08-ee46-f7501ed5a0d4"
      },
      "source": [
        "# Get most common tags\n",
        "tags_to_use = 35\n",
        "tag_freq_dict_sorted = dict(sorted(tag_freq_dict.items(), key=lambda x: x[1], reverse=True))\n",
        "final_tags = list(tag_freq_dict_sorted.keys())[:tags_to_use]\n",
        "len(final_tags)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_Rm3caDSzeW"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "import inflect\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "def tokenize_text(text):\n",
        "    \"Apply tokenization using spacy to docstrings.\"\n",
        "    tokens = EN.tokenizer(text)\n",
        "    return [token.text.lower() for token in tokens if not token.is_space]\n",
        "\n",
        "def to_lowercase(words):\n",
        "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = word.lower()\n",
        "        new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def remove_punctuation(words):\n",
        "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
        "        if new_word != '':\n",
        "            new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def remove_stopwords(words):\n",
        "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        if word not in stopwords.words('english'):\n",
        "            new_words.append(word)\n",
        "    return new_words\n",
        "\n",
        "def normalize(words):\n",
        "    words = to_lowercase(words)\n",
        "    words = remove_punctuation(words)\n",
        "    # words = remove_stopwords(words)\n",
        "    return words\n",
        "\n",
        "def tokenize_code(text):\n",
        "    \"A very basic procedure for tokenizing code strings.\"\n",
        "    return RegexpTokenizer(r'\\w+').tokenize(text)\n",
        "\n",
        "def preprocess_text(text):\n",
        "    return ' '.join(normalize(tokenize_text(text)))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGSE3-Q6ZsG5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbb73a5b-bb6f-46a9-971e-5d737af8958f"
      },
      "source": [
        "import gensim \n",
        "\n",
        "W2V_SIZE = 300\n",
        "W2V_WINDOW = 7\n",
        "W2V_EPOCH = 64\n",
        "W2V_MIN_COUNT = 20\n",
        "import numpy as np\n",
        "\n",
        "# Collect corpus for training word embeddings\n",
        "# 2 3 4 5 6\n",
        "# documents = [_text.split() for _text in np.array(df.Description)]\n",
        "documents=[_text.split() for _text in np.array(df[df.keys()[2]])]\n",
        "documents+=[_text.split() for _text in np.array(df[df.keys()[3]])]\n",
        "\n",
        "\n",
        "w2v_model = gensim.models.word2vec.Word2Vec(size=W2V_SIZE, \n",
        "                                            window=W2V_WINDOW, \n",
        "                                            min_count=W2V_MIN_COUNT, \n",
        "                                            workers=8)\n",
        "w2v_model.build_vocab(documents)\n",
        "words = w2v_model.wv.vocab.keys()\n",
        "vocab_size = len(words)\n",
        "print(\"Vocab size\", vocab_size)\n",
        "# Train Word Embeddings\n",
        "w2v_model.train(documents, total_examples=len(documents), epochs=W2V_EPOCH)\n",
        "w2v_model.save('word2vec_embeddings.bin')\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size 7837\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLq_FffIm37h"
      },
      "source": [
        "# Load pre-trained embeddings\n",
        "import gensim \n",
        "\n",
        "W2V_SIZE = 300\n",
        "W2V_WINDOW = 7\n",
        "W2V_EPOCH = 32\n",
        "W2V_MIN_COUNT = 10\n",
        "import numpy as np\n",
        "w2v_model = gensim.models.word2vec.Word2Vec.load('word2vec_embeddings.bin')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeFXdiyPDe-2",
        "outputId": "d70c8b2a-997c-4449-e4ec-f65985eb421a"
      },
      "source": [
        "# Tokenizing\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "# Max number of words in each complaint.\n",
        "MAX_SEQUENCE_LENGTH = 300\n",
        "# This is fixed.\n",
        "EMBEDDING_DIM = 300\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df['Description'])\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index)\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "# saving\n",
        "import pickle\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 99134 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-rbjEYzDW1H"
      },
      "source": [
        "def question_to_vec(question, embeddings, dim=300):\n",
        "    question_embedding = np.zeros(dim)\n",
        "    valid_words = 0\n",
        "    for word in question.split(' '):\n",
        "        # print(word)\n",
        "        # print(embeddings)\n",
        "        if embeddings.__contains__(word):\n",
        "            valid_words += 1\n",
        "            question_embedding += embeddings[word]\n",
        "    if valid_words > 0:\n",
        "        return question_embedding/valid_words\n",
        "    else:\n",
        "        return question_embedding"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUXr1O43Dc-o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e9deec8-9db0-467a-8e01-1aaaac26f893"
      },
      "source": [
        "\n",
        "all_title_embeddings = []\n",
        "for title in df.Summary:\n",
        "    all_title_embeddings.append(question_to_vec(title, w2v_model))\n",
        "all_title_embeddings = np.array(all_title_embeddings)\n",
        "\n",
        "embeddings = pd.DataFrame(data = all_title_embeddings)\n",
        "embeddings.to_csv('title_embeddings.csv', index=False)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBL5KSITDm3Z"
      },
      "source": [
        "all_title_embeddings = pd.read_csv('title_embeddings.csv').values"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvFpkmKu4AtR"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 300\n",
        "import pickle\n",
        "with open('tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJdLjP6P_YnI",
        "outputId": "72e69a97-1056-4b30-c0ee-52f64413daad"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJJ_Gq7k3muZ"
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A960wx7tASOJ"
      },
      "source": [
        "## Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "h1o2cazxF1Pa",
        "cellView": "form",
        "outputId": "f4471a0f-72a9-4799-d72d-a490608991db"
      },
      "source": [
        "#@title Output\n",
        "\n",
        "\n",
        "from IPython.display import HTML\n",
        "import logging\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "search_string = \"Delay cells in IO paths in postroute causing setup violations\" #@param {type:\"string\"}\n",
        "search_string = ' '.join(normalize(tokenize_text(search_string)))\n",
        "results_returned = \"5\" #@param {type:\"string\"}\n",
        "search_vect = np.array([question_to_vec(search_string, w2v_model)])    # Vectorize the user query\n",
        "\n",
        "# Calculate Cosine similarites for the query and all titles\n",
        "cosine_similarities = pd.Series(cosine_similarity(search_vect, all_title_embeddings)[0])\n",
        "\n",
        "# Custom Similarity Measure\n",
        "cosine_similarities = cosine_similarities*(1)\n",
        "\n",
        "output =\"\"\n",
        "for i,j in cosine_similarities.nlargest(int(results_returned)).iteritems():\n",
        "    \n",
        "    output += '<h2>' + df['Summary'][i] + '</h2>'\n",
        "    output += '<h3> Issue Key: ' + df['Issue key'][i] + '</h3>'\n",
        "    output += '<h3> Similarity Score: ' + str(j) + '</h3>'\n",
        "    output +='<p style=\"font-family:verdana; font-size:110%;\"> '\n",
        "    for i in df.Description[i][:1000].split():\n",
        "        if i.lower() in search_string:\n",
        "            output += \" <b>\"+str(i)+\"</b>\"\n",
        "        else:\n",
        "            output += \" \"+str(i)\n",
        "    output += \"</p><hr>\"\n",
        "    \n",
        "output = '<h3>Results:</h3>'+output\n",
        "display(HTML(output))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Results:</h3><h2>Nvidia: T234: Delay cells in IO paths in postroute causing setup violations</h2><h3> Issue Key: P10051779-169549</h3><h3> Similarity Score: 0.9231262445083437</h3><p style=\"font-family:verdana; font-size:110%;\">  Hi, There are <b>delay</b> <b>cells</b> seen <b>in</b> <b>IO</b> <b>paths</b> <b>in</b> route/postroute db <b>causing</b> chiplet level <b>setup</b> violations. Following are the details: +NVIDIA VPN instructions+ 1. Download the new Cisco Anyconnect VPN client from below Synopsys one-drive link [https://synopsys-my.sharepoint.com/:u:/p/pathrabe/ERKsCModtpBGlDY6y94jehIBEDqofBk7UyqAywxbrnyPdw?e=rZD07y] 2. Install the client 3. Start the Cisco Anyconnect client once installed and connect to --> ngvpn01.nvidia.com (please type this instead is <b>using</b> drop-down menu) 4. Choose \"PARTNER\" from the drop down menu for Group: 5. Use the user/password pair from below to connect to VPN login : vbaragali password : AC@nvda21 6. Connect to the VNC session provided by the AC and use the credentials they provided for the VNC.Please use only RealVNC. VNC session: synopsys-chamber-xterm-02.nvidia.com:27 username: skhayadada password: AC@nvda21 7. After opening the terminal, enter “xterm &” and <b>a</b> new window will pop up. 8.</p><hr><h2>ICC2 Down sizing cells causing setup violations</h2><h3> Issue Key: P10051779-80650</h3><h3> Similarity Score: 0.787621096439061</h3><p style=\"font-family:verdana; font-size:110%;\">  Hello, While running ICC2 RM <b>on</b> <b>a</b> TSMC 180nm block, CTS is downsizing the <b>cells</b> <b>in</b> the data <b>path</b> of REGOUT <b>path</b> <b>causing</b> <b>setup</b> violations. <b>Setup</b> slack for the <b>path</b> before CTS is -0.034 and after CTS it is -2.099286 This <b>path</b> is left unfixed even after route_opt stage. Apart from RM, we have tried running CTS with just synthesize_clock_tree clock_opt -from final_opto but there is no change. This is happening <b>on</b> few other REGOUT <b>paths</b> <b>in</b> the design. Atatching the timing reports before and after CTS for <b>a</b> quick reference. Please check the design and let <b>us</b> know what is <b>causing</b> the issue. Customer is going for tapeout <b>in</b> the next week, so it would be greaty helpful if you can provide <b>a</b> quick update. Thanks <b>a</b> lot.</p><hr><h2>tsmc7 Seeing HVT cells in critical setup paths after clock_opt</h2><h3> Issue Key: P10051779-109436</h3><h3> Similarity Score: 0.7817016757067585</h3><p style=\"font-family:verdana; font-size:110%;\">  There are HVT <b>cells</b> <b>in</b> critical <b>setup</b> <b>paths</b> after postcts. Here is <b>a</b> load script to load the database: /home/scratch.edwliu/GVASM0SMIO_HVT/GVASM0SMIO_for_chamber_7nm/load.tcl Here are some timing reports to look <b>at</b> (look for <b>cell</b> HFSBUF_504536/Z) /home/scratch.edwliu/GVASM0SMIO_HVT/GVASM0SMIO_for_chamber_7nm/tt This is <b>causing</b> <b>a</b> <b>violation</b> to many endpoints <b>causing</b> <b>a</b> qor degradation: Please check the testcase, it is <b>in</b> the NVIDIA chamber. +++++NVIDIA VPN instructions+++ 1. Please go to http://www.nvidia.com/content/includes/anyconnect.html and download the new Cisco Anyconnect VPN client for your <b>OS</b> 2. Install the client 3. Start the Cisco Anyconnect client once installed and connect to --> ngvpn01.nvidia.com (please type this instead is <b>using</b> drop-down menu) 4. Choose \"PARTNER\" from the drop down menu for Group: 5. Use the user/password pair from below to connect to VPN login : nmoore passwd : AC@nvda12 6. Connect to the VNC session provided by the AC and use the creden</p><hr><h2>Interpretation of set_multicycle_path is causing huge hold violations in ICC2</h2><h3> Issue Key: P10051779-103531</h3><h3> Similarity Score: 0.7621524862636293</h3><p style=\"font-family:verdana; font-size:110%;\">  ~~~~~~~~~~ Access Restrictions ~~~~~~~~~~ Data is <b>in</b> the AMD secure area. You should have access to the \"sdv_amd\" group to access data. If you need access, please send an email directly to \"ge-sdv_amd@synopsys.com\", not me. Unfortunately, AMD doesn't give access to folks <b>in</b> China. ~~~~~~~~~~ Problem Description ~~~~~~~~~~ Problem seen with the sdc interpretation of 'set_multicycle_path' <b>in</b> ICC2. ICC2 is reporting huge hold violations. Customer debugged and narrowed it down to the interpretation of <b>a</b> multi cycle path. They claim that ICC did not have such <b>a</b> <b>violation</b> with the same constraints. ~~~~~~~~~~ Test Case ~~~~~~~~~~ Directory: /global/gtsamd4/users/prasadl/9001156473_8000981430_sdc_issue/test_case/runs/I2OptCts Run Script: runme.csh Once the run is complete, have <b>a</b> look the following timing report to see the huge hold violations: rpts_uncompressed/I2OptCts/pre_opt/REFCLK_25_FuncTT0p9v_min.rpt Multi-cycle <b>path</b> is define as below: set_multicycle_path 20 \\ -setup \\</p><hr><h2>Difference in timing reports (No paths vs paths reported) between 19.03,19.03SP1</h2><h3> Issue Key: P10051779-75895</h3><h3> Similarity Score: 0.7183542113679217</h3><p style=\"font-family:verdana; font-size:110%;\">  ########### Important: <b>I</b> was informed by Global Account team, that Micron asks SNPS to adhere their data access restriction by not granting secure server access to SNPS members from China office. Therefore please be so kind and re-assign to different R&D. For further questions, please contact Sreedhar Tallapaneni <tallapan@synopsys.com> Many Thanks Frank ########### Hi , <b>In</b> customer design, with 19.03 release version, we are seeing \"No Paths\" with \"report_timing -from rcv_ac_ab/clk_tcheckpin1 -pba_mode path\". Note that \"report_timing -from rcv_ac_ab/clk_tcheckpin1 -pba_mode none\" is showing paths. But with 19.03-SP1 release version, we are seeing the timing report. What could be the reason for this? Also customer wants to stick to 19.03 release version for his current project. So <b>in</b> this regard, could you please help backport the fix (if any) <b>in</b> 19.03-SP1 to 19.03 builds/upcoming <b>T</b> builds? Reports: **************************************** Report : timing -path_type full</p><hr>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}